+-------------------------------------------------------------------------------------
Warm Up
+-------------------------------------------------------------------------------------
#-> An efficient algorithm executes in minimum time and with minimum memory space.
#-> Studying data structures is all about learning data management techniques.
#-> The term "data" means a value or a set of values.
#-> A data item that does not have subordinate data items is categorized as an
    elementary item.
#-> A data item composed of one or more subordinate data items is called a group
    item.
#-> A record is a collection of data items.
#-> A file is a collection of related records.
#-> The data item that uniquely identifies a record is called a primary key.
#-> An ADT exposes what it does and not how it does.


+-------------------------------------------------------------------------------------
Classification of Data Structures
+-------------------------------------------------------------------------------------

#-> Primitive & Non-Primitive
#-> Linear & Non-Linear

#-> Note: Arrays, linked lists, stack, queues are linear data structures. They are
    stored in memory in sequential order.
#-> Note: Trees and graphs are non-linear data structures.
#-> The relationship of adjacency is not maintained in  non-linear data structures.


+-------------------------------------------------------------------------------------
Overview of Basic Data Structures
+-------------------------------------------------------------------------------------

ARRAYS

#-> A collection of similar data items, stored contiguously, and referenced by an
    index (also called subscript).
#-> Its size is fixed hence static.
#-> Insertion and deletion requires shifting of elements from their positions.

LINKED LISTS

#-> Composed of nodes in a sequential manner.
#-> It is dynamic and no size declaration is required.
#-> Easier to insert or delete data elements.
#-> Slow search operation.
#-> Requires more memory.

STACKS

#-> A LIFO data structure.
#-> Insertion and deletion of data items done at only one end.
#-> It is implemented using array or linked list.
#-> It maintains a variable "top" that refers to the topmost element of the stack.
#-> It also maintains a variable called MAX to specify the permitted stack size.
#-> top = NULL indicates the stack is empty.
#-> top = MAX-1 indicates the stack is full.
#-> Before inserting an item, we must check for overflow condition.
#-> Before deleting an item, we must check for underflow condition.

QUEUES

#-> A FIFO data structure.
#-> Insertion happens at rear end.
#-> Deletion happens at front end.
#-> Impelemented using array or linked list.
#-> It maintains "front" and "rear" pointers.
#-> It also maintains a variable called MAX to specify the permitted queue size.
#-> rear = MAX-1 indicates the queue is full.
#-> front = NULL && rear = NULL indicates the queue is empty.
#-> Before inserting an item, we must check for overflow condition.
#-> Before deleting an item, we must check for underflow condition.

TREES

#-> A non-linear data structure composed of nodes arranged in a heirarchical manner.
#-> It begins with a root node and remaining nodes are partitioned as left and right
    sub-trees.
#-> It represent parent-child like heirarchy.
#-> A node is allowed to have any number of childrens but one parent.
#-> It maintains pointer called root.
#-> root = NULL indicates the tree is empty.
#-> Provides quick search, inserte, and delete operations.
#-> Complicated deletion algorithm.

GRAPHS

#-> A non-linear data structure composed of nodes (called vertices) and edges
    connecting these nodes.                             -
#-> It is a genralized tree capable of having complex relationships apart from
    parent-child.
#-> They do not have any root node.
#-> Every node can be connected with every other node.
#-> Two nodes connected via an edge are called neighbours.
#-> Often used to model real-world situations like finding the shortest path between
    two nodes.
#-> Its implemented algorithms are often complicated and slow.


+-------------------------------------------------------------------------------------
Operations On Data Structures
+-------------------------------------------------------------------------------------

TRAVERSING, SEARCHING, INSERTING, DELETING, SORTING, MERGING


+-------------------------------------------------------------------------------------
Abstract Data Type
+-------------------------------------------------------------------------------------

#-> An ADT exposes what it does, not how.
#-> It exposes a set of public interfaces to communicate.


+-------------------------------------------------------------------------------------
ALGORITHMS
+-------------------------------------------------------------------------------------

#-> An algorithm provides a blueprint for solving a problem in finite number of steps.
#-> An algorithm is designed using a top-down or a bottom-up approach.

TOP-DOWN APPROACH

#-> Divides a complex algorithm into one or more modules and sub-modules.
#-> It starts from an abstract design and moves towards more concrete levels.

BOTTOM-UP APPROACH

#-> Starts froma comcrete implementation up towards the abstract design.


+-------------------------------------------------------------------------------------
TIME & SPACE COMPLEXITY
+-------------------------------------------------------------------------------------

#-> An algorithm consumes time and memory needed for its execution.
#-> This makes time and space a good measurement of calculating an algorithm's
    efficiency and complexity.
#-> Time complexity determines the running time of a program as a function of the
    input size.
#-> Space complexity determines the amount of runtime memory consumed as a function
    of the input size.
#-> We are interested in studying time complexity.
#-> Instead of expressing the time complexity in a concrete time-format such as
    milli-seconds, we are interested in the number of machine instructions which a
    program executes.


WORST-CASE RUNNING TIME

#-> Represents the worst-case runtime behavior of an algorithm with respect to
    the input size.
#-> It gives us an assurance of "no matter what, the algorithm will never go beyond
    this time limit".
#-> It estimates the upper bound on the running time for any given input size.


AVERAGE-CASE RUNNING TIME

#-> This studies how the algorithm behaves when the input is randomly drawn from a
    given distribution assuming all inputs of a given size are equally likely?
#->


BEST-CASE RUNNING TIME

#-> It represents the time complexity under the most ideal and optimal situations.
#-> Of course, this is of less interest.



TIME-SPACE TRADE-OFF

#-> When space is a big constraint, we may trade-off some CPU time and vice versa.


+-------------------------------------------------------------------------------------
EXPRESSING ALGORITHM EFFICIENCY
+-------------------------------------------------------------------------------------

#-> The efficiency of an algorithm is expressed as a function f(n) of the input size n
    for a given instance of the problem.
#-> A linear statement is assumed to be executed as one machine instruction.
#-> A efficiency of a procedure containing 5 linear statements will be f(n) = 5;


LINEAR LOOPS

#-> The number of iterations in a loop is directly proportional to the loop factor. The
    following loop's efficiency is f(n) = 3n.

    for(int i = 0; i < n; i++) {
        linear-statement1;
        linear-statement2;
        linear-statement3;
    }

#-> The following loop has an efficiency f(n) = 3n/2.

    for(int i = 0; i < n; i += 2) {
        linear-statement1;
        linear-statement2;
        linear-statement3;
    }

NOTE: Linear loop have their loop-variable incremented or decremented.


LOGARITHMIC LOOPS

#-> How many times the following loop executes?

    for(int i = 0; i < 1000; i *= 2) {
        statement;
    }

    Only 10 times because log1000 = 10.

NOTE: Logarithmic loops have their loop-variable multiplied or divided.


LINEAR LOGARITHMIC LOOP

    for(int i = 0; i < 1000; i++) {
        for(int j = 0; j < 1000; j *= 2) {
            statement;
        }
    }

    f(n) = nlogn

QUADRATIC LOOP

    for(int i = 0; i < 1000; i++) {
        for(int j = 0; j < 1000; j++) {
            statement;
        }
    }


    f(n) = n pow 2

DEPENDENT QUADRATIC LOOP

    for(int i = 0; i < 10; i++) {
        for(int j = 0; j <= i; j++) {
            statement;
        }
    }

    f(n) = n(n+1)/2


+-------------------------------------------------------------------------------------
Big-Oh Notation
+-------------------------------------------------------------------------------------

Most algorithms perform well with small input sizes. Big-Oh notation is a scientific
way to express the cost of an algorithm with large input sizes in consideration. It
expresses the worst-case complexity of an algorithm.

Algorithm complexity in increasing order:

O(1), O(logn), O(n), O(nlogn), O(n^2), O(n^3), O(2^n), O(n!), O(n^n)

NOTE: 

1) Algorithms that run in constant, logarithmic, linear or superlinear time are preferred.
2) O(n logn) is called superlinear algorithm.
3) Ultimately, the asymptotic derivation comes from Calculus: Lim (n -> infinity) [n^2 = infinity]
